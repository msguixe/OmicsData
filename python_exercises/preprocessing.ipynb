{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniprot data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDs\n",
    "\n",
    "Map uniprot IDs with Hugo symbols\n",
    "\n",
    "Download a tab separated file from https://www.uniprot.org/uniprot/?query=*&fil=organism%3A%22Homo+sapiens+%28Human%29+%5B9606%5D%22+AND+reviewed%3Ayes using only the following columns:\n",
    "\n",
    "    Entry\tProtein names\tCross-reference (GeneCards)\tCross-reference (CCDS)\n",
    "\n",
    "Uncompress the file and rename it as ``uniprots_raw.tsv``\n",
    "\n",
    "The data was downloaded on 03/07/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "info_isoforms = pd.read_csv(\"external/uniprots_raw.tsv\", sep=\"\\t\")\n",
    "\n",
    "# For each isoform get its CCDS\n",
    "l = []\n",
    "d = set()\n",
    "for index,row in info_isoforms.iterrows():\n",
    "    entry = row[\"Entry\"]\n",
    "    try:\n",
    "        hugo = row[\"Cross-reference (GeneCards)\"][:-1]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    for ccds in str(row[\"Cross-reference (CCDS)\"]).split(\";\"):\n",
    "        ccds = ccds.strip()\n",
    "        v = ccds.split(\" \")\n",
    "        if len(v) == 2:\n",
    "            cds = v[0]\n",
    "            entry_id = str(v[1])[1:-1]\n",
    "            \n",
    "        elif v[0] ==\"\":\n",
    "            cds = \"-\"\n",
    "            entry_id = entry+\"-1\"\n",
    "            if entry_id in d:\n",
    "                continue\n",
    "            \n",
    "           \n",
    "        else:\n",
    "            cds = v[0]\n",
    "            entry_id = entry+\"-1\"\n",
    "        d.add(entry_id)\n",
    "        l.append([entry,hugo,cds,entry_id])\n",
    "\n",
    "df_uniprot = pd.DataFrame(l,columns=[\"Entry\",\"Hugo_Symbol\",\"CCDS\",\"Entry_Isoform\"])\n",
    "df_uniprot.to_csv(\"data/uniprot_isoforms.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences\n",
    "\n",
    "Download and uncompress the fasta files with the reference proteome of Eukaryota (files UP000005640_9606.fasta and UP000005640_9606_additional.fasta.gz)\n",
    "\n",
    "Check that they have an annotate row in the mapping dataframe, if not do not include the sequence\n",
    "\n",
    "*TODO find the right release*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from Bio import SeqIO # Requires biopython\n",
    "\n",
    "# For each sequence stores a row with the sequence and the info of the isoform\n",
    "l_data =  []\n",
    "for record in itertools.chain(SeqIO.parse('external/UP000005640_9606.fasta', \"fasta\"), \\\n",
    "                              SeqIO.parse('external/UP000005640_9606_additional.fasta', \"fasta\")):\n",
    "    entry = record.id.split(\"|\")[1]\n",
    "    if \"-\" in entry:\n",
    "        entry_isoform = entry\n",
    "        entry = entry.split(\"-\")[0]\n",
    "    else:\n",
    "        entry_isoform = entry + \"-1\"\n",
    "    l_data.append([entry,entry_isoform, \"\".join(record.seq)])\n",
    "    \n",
    "df_seqs = pd.DataFrame(l_data, columns=[\"Entry\",\"Entry_Isoform\",\"Sequence\"])\n",
    "# Check those with uniprot ID in the dataframe of uniprots\n",
    "df_uniprot = pd.read_csv('data/uniprot_isoforms.tsv', sep=\"\\t\")\n",
    "df_seqs_info = pd.merge(df_seqs, df_uniprot)\n",
    "df_seqs_info.to_csv('data/sequences_isoforms.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCGA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPPA\n",
    "\n",
    "Download level 4 cohort-specific RPPA data from https://tcpaportal.org/tcpa/download.html in a folder named ``tcga_rppa``  \n",
    "Concatenate the data and merge COAD and READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  7663\n",
      "Antibodies:  258\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_file(path, name):\n",
    "    with ZipFile(path) as zipfolder:\n",
    "        with zipfolder.open('tmp/TCGA-{}-L4.csv'.format(name)) as f:\n",
    "            return pd.read_csv(f, sep=',')\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "regex = re.compile('TCGA\\-([A-Z]+)\\-L4\\.zip')\n",
    "\n",
    "for file in os.listdir('external/tcga_rppa'):\n",
    "    match = regex.match(file)\n",
    "    if match:\n",
    "        file_path = os.path.join('external/tcga_rppa', file)\n",
    "        cancer_type = match.group(1)\n",
    "        \n",
    "        df = read_file(file_path, cancer_type)\n",
    "        df[\"Matchable_Sample_ID\"]=(df[\"Sample_ID\"]).str[0:12]\n",
    "        df.drop(columns=[\"Sample_Type\",\"SetID\",\"Sample_ID\"],inplace=True)\n",
    "\n",
    "        if cancer_type in [\"COAD\", \"READ\"]:\n",
    "            cancer_type = \"COADREAD\"\n",
    "            df[\"Cancer_Type\"] = cancer_type\n",
    "                \n",
    "        dfs.append(df)\n",
    "        \n",
    "df = pd.concat(dfs, sort=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.to_csv('data/tcga_rppa.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "print('Samples: ', len(df[\"Matchable_Sample_ID\"].unique()))\n",
    "print('Antibodies: ', len(df.columns.values)-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNASeq\n",
    "\n",
    "Download cohort specific RNASeq data from https://gdc.cancer.gov/about-data/publications/pancanatlas in a folder named ``tcga_rna``\n",
    "Files required are: ``EBPlusPlusAdjustPANCAN_IlluminaHiSeq_RNASeqV2.geneExp.tsv`` and ``merged_sample_quality_annotations.tsv``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  10087\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def coadread_mapping(ctype):\n",
    "    if ctype in [\"COAD\", \"READ\"]:\n",
    "        return \"COADREAD\"\n",
    "    else:\n",
    "        return ctype\n",
    "    \n",
    "# Read antibodies and their associated hugo\n",
    "hugos = pd.read_csv('internal/antibody_parsed.csv', sep=\",\")[\"Hugo_Symbol\"].unique()\n",
    "\n",
    "df_info_samples = pd.read_csv(\"external/tcga_rna/merged_sample_quality_annotations.tsv\",sep=\"\\t\")\n",
    "samples_filtered = df_info_samples[(df_info_samples[\"platform\"].str.contains(\"_RNASeqV2\"))&(~df_info_samples[\"Do_not_use\"])&(~pd.isnull(df_info_samples[\"cancer type\"]))][[\"aliquot_barcode\",\"cancer type\"]].drop_duplicates()\n",
    "\n",
    "df_rna = pd.read_csv(\"external/tcga_rna/EBPlusPlusAdjustPANCAN_IlluminaHiSeq_RNASeqV2.geneExp.tsv\",sep=\"\\t\")\n",
    "df_rna[\"Hugo_Symbol\"] = df_rna.apply(lambda row: row[\"gene_id\"].split(\"|\")[0],axis=1)\n",
    "df_rna = df_rna[df_rna[\"Hugo_Symbol\"]!=\"?\"]\n",
    "df_rna.drop(\"gene_id\",axis=1,inplace=True)\n",
    "\n",
    "df_rna = df_rna.melt(id_vars=\"Hugo_Symbol\",value_name=\"RSEM\",var_name=\"aliquot_barcode\").merge(samples_filtered,how=\"right\")\n",
    "df_rna = df_rna[df_rna['Hugo_Symbol'].isin(hugos)]\n",
    "df_rna.rename(columns={\"aliquot_barcode\":\"Tumor_Sample_Barcode\", \"cancer type\": \"Cancer_Type\"},inplace=True)\n",
    "df_rna[\"Cancer_Type\"] = df_rna[\"Cancer_Type\"].map(coadread_mapping)\n",
    "df_rna[\"Matchable_Sample_ID\"] = df_rna[\"Tumor_Sample_Barcode\"].str[0:12]\n",
    "df_rna.drop(columns=[\"Tumor_Sample_Barcode\"],inplace=True)\n",
    "df_rna=df_rna.groupby([\"Hugo_Symbol\",\"Matchable_Sample_ID\",\"Cancer_Type\"],as_index=False).agg({\"RSEM\":np.nanmean})\n",
    "df_rna[\"log2(RSEM)\"] = np.log2(df_rna[\"RSEM\"] + 0.0001)\n",
    "\n",
    "df_rna.to_csv('data/tcga_rna.tsv.gz', sep=\"\\t\", compression=\"gzip\", index=False)\n",
    "\n",
    "print('Samples: ', len(df_rna[\"Matchable_Sample_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNA\n",
    "\n",
    "Download cohort specific CNA data from http://gdac.broadinstitute.org/runs/analyses__latest/data/ (version 2016_01_28) in a folder named ``tcga_cna``. Download the files ending in ``CopyNumber_Gistic2.Level_4.2016012800.0.0.tar.gz``\n",
    "\n",
    "Limit to the same cancer types as the ones for RPPA data (skip COAD and READ and get only COADREAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples  10845\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "# Read antibodies and their associated hugo\n",
    "hugos = [str(x) for x in list(pd.read_csv('internal/antibody_parsed.csv', sep=\",\")[\"Hugo_Symbol\"].unique())]\n",
    "\n",
    "# Read data\n",
    "list_values = []\n",
    "for file in os.listdir('external/tcga_cna/'):\n",
    "    cancer_type = file.split('-')[0].replace('gdac.broadinstitute.org_', '')\n",
    "    tar = tarfile.open(\"external/tcga_cna/{}\".format(file), \"r:gz\")\n",
    "    f = tar.extractfile('{}/all_thresholded.by_genes.txt'.format(file.replace('.tar.gz', '')))\n",
    "    df = pd.read_csv(f, sep=\"\\t\", error_bad_lines=False)\n",
    "    \n",
    "    df_cna = pd.melt(df, id_vars=[\"Gene Symbol\",\"Locus ID\",\"Cytoband\"], var_name=\"Tumor_Sample_Barcode\", value_name=\"CNA\")\n",
    "    df_cna[\"Matchable_Sample_ID\"] = df_cna[\"Tumor_Sample_Barcode\"].str[0:12]\n",
    "    df_cna[\"Cancer_Type\"] = cancer_type\n",
    "    df_cna.drop(\"Tumor_Sample_Barcode\", axis=1, inplace=True)\n",
    "    df_cna = df_cna[df_cna[\"Gene Symbol\"].isin(hugos)]\n",
    "    list_values.append(df_cna)\n",
    "\n",
    "df_cna = pd.concat(list_values).drop_duplicates()\n",
    "df_cna.rename(columns={\"Gene Symbol\":\"Hugo_Symbol\"},inplace=True)\n",
    "df_cna.to_csv('data/tcga_cna.tsv.gz', compression=\"gzip\", sep=\"\\t\")\n",
    "\n",
    "print('Samples ', len(df_cna[\"Matchable_Sample_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutational data\n",
    "\n",
    "Download cohort specific somatic mutations data from https://gdc.cancer.gov/about-data/publications/pancanatlas (``mc3.v0.2.8.PUBLIC.maf.gz``) with supplementary tables from https://gdc.cancer.gov/resources-tcga-users/tcga-code-tables in a folder named ``tcga_mutations\".\n",
    "\n",
    "Required tables from suplementary material are:\n",
    "\n",
    "- TCGA Study Abbreviations (``diseaseStudy.tsv``)\n",
    "- Tissue Source Site Codes (``tissueSourceSite.tsv``)\n",
    "\n",
    "The following filters are applied:\n",
    "- only alterations that pass the filter \"PASS\"\n",
    "- all alterations in the same gene are combined \n",
    "- Phenotype is selected from this order of priority\n",
    "[\"Splice_Site\",\"Nonsense_Mutation\",\"Frame_Shift_Del\",\"Frame_Shift_Ins\",\"Nonstop_Mutation\",\"Translation_Start_Syte\",\"In_Frame_Del\",\"In_Frame_Ins\"\n",
    ",\"Missense_Mutation\",\"Intron\",\"Silent\",\"5'UTR\",\"3'UTR\",\"IGR\",\"5'Flank\",\"3'Flank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples  9104\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def coadread_mapping(ctype):\n",
    "    if ctype in [\"COAD\", \"READ\"]:\n",
    "        return \"COADREAD\"\n",
    "    else:\n",
    "        return ctype\n",
    "    \n",
    "def list_samples(group, dict_):\n",
    "    dict_[group.name] = list(set(group['Matchable_Sample_ID'].unique()))\n",
    "    \n",
    "def get_protein_mutation(row):\n",
    "    try:\n",
    "        pos=int(row[\"Protein_position\"])\n",
    "    except ValueError:\n",
    "        return \".\"\n",
    "    wtaa=row[\"Amino_acids\"].split(\"/\")[0]\n",
    "    if \"/\" in row[\"Amino_acids\"]:\n",
    "        mtaa = row[\"Amino_acids\"].split(\"/\")[1]\n",
    "    else:\n",
    "        mtaa = wtaa\n",
    "    return wtaa+str(pos)+mtaa\n",
    "\n",
    "def concat(grp):\n",
    "    l = list(grp)\n",
    "    return \",\".join([str(e) for e in list(grp)])\n",
    "\n",
    "def select_phenotype(row):\n",
    "    \n",
    "    values = row[\"Variant_Classification\"].split(\",\")\n",
    "    # List of prioritys from the TCGA data\n",
    "    list_priority = [\"Splice_Site\",\"Nonsense_Mutation\",\"Frame_Shift_Del\",\"Frame_Shift_Ins\",\"Nonstop_Mutation\",\"Translation_Start_Syte\",\"In_Frame_Del\",\"In_Frame_Ins\",\"Missense_Mutation\",\"Intron\",\"Silent\",\"5'UTR\",\"3'UTR\",\"IGR\",\"5'Flank\",\"3'Flank\"]\n",
    "                     \n",
    "    for priority in list_priority:\n",
    "        if priority in values:\n",
    "            return priority\n",
    "    return \"-\"\n",
    "\n",
    "\n",
    "# Load info\n",
    "df_info_samples = pd.read_csv(\"external/tcga_mutations/tissueSourceSite.tsv\", sep=\"\\t\", keep_default_na=False)\n",
    "df_ttypes_names = pd.read_csv(\"external/tcga_mutations/diseaseStudy.tsv\",sep=\"\\t\")\n",
    "df_info_samples = df_info_samples.merge(df_ttypes_names, on=[\"Study Name\"])\n",
    "df_info_samples.rename(columns={\"Study Abbreviation\":\"Cancer_Type\"},inplace=True)\n",
    "\n",
    "samples_filtered = df_info_samples[[\"TSS Code\",\"Cancer_Type\"]].drop_duplicates()\n",
    "d_ttype = dict(zip(samples_filtered[\"TSS Code\"], samples_filtered[\"Cancer_Type\"]))\n",
    "\n",
    "# Load mutations\n",
    "df_muts = pd.read_csv(\"external/tcga_mutations/mc3.v0.2.8.PUBLIC.maf.gz\", sep=\"\\t\", low_memory=False)\n",
    "df_muts[\"Cancer_Type\"] = df_muts.apply(lambda row: d_ttype[row[\"Tumor_Sample_Barcode\"].split(\"-\")[1]], axis=1)\n",
    "\n",
    "df_muts[\"Matchable_Sample_ID\"] = df_muts[\"Tumor_Sample_Barcode\"].str[0:12]\n",
    "\n",
    "# list distinc samples IDs per cancer type\n",
    "# TODO needed?\n",
    "# TODO merge COADREAD before?, filter PASS before?\n",
    "d_total_mutations = {}\n",
    "df_muts.groupby(\"Cancer_Type\").apply(list_samples, dict_=d_total_mutations)\n",
    "with open(\"data/tcga_muts_samples.json\", 'w') as fd:\n",
    "    json.dump(d_total_mutations, fd)\n",
    "\n",
    "df_muts = df_muts[df_muts[\"FILTER\"]==\"PASS\"]\n",
    "df_muts[\"Cancer_Type\"] = df_muts[\"Cancer_Type\"].map(coadread_mapping)\n",
    "\n",
    "df_muts[\"protein_mutation\"] = df_muts.apply(lambda row: get_protein_mutation(row),axis=1)\n",
    "    \n",
    "    \n",
    "df_muts = df_muts[[\"Matchable_Sample_ID\",\"Hugo_Symbol\",\"Cancer_Type\",\"Chromosome\",\"Start_Position\",\"End_Position\",\"Strand\",\"Reference_Allele\",\"Tumor_Seq_Allele2\",\"Protein_position\",\"protein_mutation\",\"Variant_Classification\",\"CCDS\",\"Variant_Type\"]].drop_duplicates()\n",
    "df_muts = df_muts.groupby([\"Hugo_Symbol\",\"Matchable_Sample_ID\",\"CCDS\",\"Cancer_Type\"],as_index=False).agg({\"Chromosome\":concat,\"Start_Position\":concat,\"End_Position\":concat,\"Strand\":concat,\"Variant_Classification\":concat,\"Reference_Allele\":concat,\"Tumor_Seq_Allele2\":concat,\"Protein_position\":concat,\"protein_mutation\":concat,\"Variant_Type\":concat})\n",
    "\n",
    "df_muts[\"Phenotype\"] = df_muts.apply(lambda row: select_phenotype(row),axis=1)\n",
    "\n",
    "df_muts.drop_duplicates().to_csv(\"data/tcga_muts.tsv.gz\", sep=\"\\t\", compression=\"gzip\", index=False)\n",
    "\n",
    "print('Samples ', len(df_muts[\"Matchable_Sample_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples  9104\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def coadread_mapping(ctype):\n",
    "    if ctype in [\"COAD\", \"READ\"]:\n",
    "        return \"COADREAD\"\n",
    "    else:\n",
    "        return ctype\n",
    "    \n",
    "def list_samples(group, dict_):\n",
    "    dict_[group.name] = list(set(group['Matchable_Sample_ID'].unique()))\n",
    "    \n",
    "def get_protein_mutation(row):\n",
    "    try:\n",
    "        pos=int(row[\"Protein_position\"])\n",
    "    except ValueError:\n",
    "        return \".\"\n",
    "    wtaa=row[\"Amino_acids\"].split(\"/\")[0]\n",
    "    if \"/\" in row[\"Amino_acids\"]:\n",
    "        mtaa = row[\"Amino_acids\"].split(\"/\")[1]\n",
    "    else:\n",
    "        mtaa = wtaa\n",
    "    return wtaa+str(pos)+mtaa\n",
    "\n",
    "def concat(grp):\n",
    "    l = list(grp)\n",
    "    return \",\".join([str(e) for e in list(grp)])\n",
    "\n",
    "def select_phenotype(row):\n",
    "    \n",
    "    values = row[\"Variant_Classification\"].split(\",\")\n",
    "    # List of prioritys from the TCGA data\n",
    "    list_priority = [\"Splice_Site\",\"Nonsense_Mutation\",\"Frame_Shift_Del\",\"Frame_Shift_Ins\",\"Nonstop_Mutation\",\"Translation_Start_Syte\",\"In_Frame_Del\",\"In_Frame_Ins\",\"Missense_Mutation\",\"Intron\",\"Silent\",\"5'UTR\",\"3'UTR\",\"IGR\",\"5'Flank\",\"3'Flank\"]\n",
    "                     \n",
    "    for priority in list_priority:\n",
    "        if priority in values:\n",
    "            return priority\n",
    "    return \"-\"\n",
    "\n",
    "\n",
    "# Load info\n",
    "df_info_samples = pd.read_csv(\"external/tcga_mutations/tissueSourceSite.tsv\", sep=\"\\t\", keep_default_na=False)\n",
    "df_ttypes_names = pd.read_csv(\"external/tcga_mutations/diseaseStudy.tsv\",sep=\"\\t\")\n",
    "df_info_samples = df_info_samples.merge(df_ttypes_names, on=[\"Study Name\"])\n",
    "df_info_samples.rename(columns={\"Study Abbreviation\":\"Cancer_Type\"},inplace=True)\n",
    "df_test = pd.read_csv(\"external/TCGA-CDR-SupplementalTableS1.csv\",sep=\"\\t\")\n",
    "\n",
    "\n",
    "\n",
    "samples_filtered = df_info_samples[[\"TSS Code\",\"Cancer_Type\"]].drop_duplicates()\n",
    "d_ttype = dict(zip(samples_filtered[\"TSS Code\"], samples_filtered[\"Cancer_Type\"]))\n",
    "\n",
    "# Load mutations\n",
    "df_muts = pd.read_csv(\"external/tcga_mutations/mc3.v0.2.8.PUBLIC.maf.gz\", sep=\"\\t\", low_memory=False)\n",
    "df_muts = df_muts[df_muts[\"FILTER\"]==\"PASS\"]\n",
    "df_muts[\"Cancer_Type\"] = df_muts.apply(lambda row: d_ttype[row[\"Tumor_Sample_Barcode\"].split(\"-\")[1]], axis=1)\n",
    "df_muts[\"Matchable_Sample_ID\"] = df_muts[\"Tumor_Sample_Barcode\"].str[0:12]\n",
    "\n",
    "\n",
    "# list distinc samples IDs per cancer type\n",
    "\n",
    "d_total_mutations = {}\n",
    "df_muts.groupby(\"Cancer_Type\").apply(list_samples, dict_=d_total_mutations)\n",
    "with open(\"data/tcga_muts_samples.json\", 'w') as fd:\n",
    "    json.dump(d_total_mutations, fd)\n",
    "\n",
    "\n",
    "df_muts[\"Cancer_Type\"] = df_muts[\"Cancer_Type\"].map(coadread_mapping)\n",
    "df_muts[\"protein_mutation\"] = df_muts.apply(lambda row: get_protein_mutation(row),axis=1)\n",
    "df_muts = df_muts[[\"Matchable_Sample_ID\",\"Hugo_Symbol\",\"Cancer_Type\",\"Chromosome\",\"Start_Position\",\"End_Position\",\"Strand\",\"Reference_Allele\",\"Tumor_Seq_Allele2\",\"Protein_position\",\"protein_mutation\",\"Variant_Classification\",\"CCDS\",\"Variant_Type\"]].drop_duplicates()\n",
    "df_muts = df_muts.groupby([\"Hugo_Symbol\",\"Matchable_Sample_ID\",\"CCDS\",\"Cancer_Type\"],as_index=False).agg({\"Chromosome\":concat,\"Start_Position\":concat,\"End_Position\":concat,\"Strand\":concat,\"Variant_Classification\":concat,\"Reference_Allele\":concat,\"Tumor_Seq_Allele2\":concat,\"Protein_position\":concat,\"protein_mutation\":concat,\"Variant_Type\":concat})\n",
    "\n",
    "df_muts[\"Phenotype\"] = df_muts.apply(lambda row: select_phenotype(row),axis=1)\n",
    "\n",
    "df_muts.drop_duplicates().to_csv(\"data/tcga_muts.tsv.gz\", sep=\"\\t\", compression=\"gzip\", index=False)\n",
    "\n",
    "print('Samples ', len(df_muts[\"Matchable_Sample_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination\n",
    "\n",
    "Merge data (RPPA, CNA, RNA and mutations) per sample. Samples not mutated are considered WT.  \n",
    "Include which samples has an upstream E3 ligases mutated and annotate them  \n",
    "Calculate which mutations fall into the epitope region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ppi_e3 = os.path.join(base,\"preprocess/ppi/data/E3_target_annotated_interations.csv\")\n",
    "\n",
    "def concat(grp):\n",
    "    l = list(grp)\n",
    "    return \",\".join(grp)\n",
    "\n",
    "def find_altered_E3(row, d_mapping):\n",
    "    mutated = str(row[\"Ubiquitinases_Mutated\"]).split(\",\")\n",
    "    ligases = d_mapping[row[\"Hugo_Symbol\"]]\n",
    "    l = []\n",
    "    for ub in mutated:\n",
    "        if ub in ligases:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_in_recognition(row):\n",
    "    if row[\"protein_mutation\"] == \"-\":\n",
    "        return False\n",
    "    v = row[\"Epitope\"]\n",
    "    if str(v)==\"nan\" or str(v) == \"0\" or row[\"Phenotype\"]==\"WT\":\n",
    "        return False\n",
    "    if \"-\" in v:\n",
    "        start = int(v.split(\"-\")[0])\n",
    "        end = int(v.split(\"-\")[1])\n",
    "    else:\n",
    "        start = int(v)\n",
    "        end = int(v)\n",
    "    positions = row[\"Protein_position\"].split(\",\")\n",
    "    for position_raw in positions:\n",
    "        for position_indel in position_raw.split(\"-\"):\n",
    "            try:\n",
    "                position = int(position_indel)\n",
    "            except ValueError:\n",
    "                \n",
    "                continue\n",
    "            if position >= int(start) and position <= int(end):\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "# Mapping protein-Hugo\n",
    "df_antibodies=pd.read_csv(\"internal/antibody_parsed.csv\")\n",
    "d_mapping = defaultdict(list)\n",
    "for index,row in df_antibodies[[\"Hugo_Symbol\",\"Protein\"]].drop_duplicates().iterrows():\n",
    "    d_mapping[row[\"Protein\"]].append(row[\"Hugo_Symbol\"])\n",
    "\n",
    "# RPPA\n",
    "rppa = pd.read_csv(\"data/tcga_rppa.tsv\", sep=\"\\t\")\n",
    "columns=list(rppa_raw.columns.values)\n",
    "columns.remove(\"Matchable_Sample_ID\")\n",
    "columns.remove(\"Cancer_Type\")\n",
    "rppa = rppa.melt(id_vars=[\"Matchable_Sample_ID\",\"Cancer_Type\"],value_vars=columns,value_name=\"RPPA_VALUES\",var_name=\"Protein\")\n",
    "\n",
    "# discard samples with non finite RPPA\n",
    "rppa = rppa[np.isfinite(rppa[\"RPPA_VALUES\"])]\n",
    "# include Hugo ID\n",
    "rppa[\"Hugo_Symbol\"] = rppa.apply(lambda row: d_mapping[row[\"Protein\"]][0] if row[\"Protein\"] in d_mapping else \"-\" , axis=1) # Select the first hugo symbol, only one hugo per antibody\n",
    "# exclude antbodies without information\n",
    "rppa = rppa[rppa[\"Hugo_Symbol\"]!=\"-\"]\n",
    "\n",
    "# RNA\n",
    "rna = pd.read_csv(\"data/tcga_rna.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\n",
    "rna.drop(\"Tumor_Sample_Barcode\",axis=1,inplace=True)\n",
    "\n",
    "df = pd.merge(rna,rppa)\n",
    "\n",
    "# CNA\n",
    "cna = pd.read_csv(\"data/tcga_cna.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\n",
    "cna = [[\"Hugo_Symbol\",\"Matchable_Sample_ID\",\"CNA\"]].drop_duplicates()\n",
    "\n",
    "df = pd.merge(df,cna)\n",
    "\n",
    "# Mutations\n",
    "muts = pd.read_csv(\"data/tcga_muts.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\n",
    "muts = muts[[\"Hugo_Symbol\",\"CCDS\",\"Cancer_Type\",\"Phenotype\",\"protein_mutation\",\"Protein_position\",\"Variant_Classification\",\"Matchable_Sample_ID\",\"Variant_Type\"]].drop_duplicates()\n",
    "\n",
    "# Match the CCDS for each samples, if not CCDS discard them\n",
    "ccds = muts[[\"Hugo_Symbol\",\"CCDS\"]].drop_duplicates()\n",
    "df = pd.merge(df, ccds, how=\"left\")\n",
    "\n",
    "# Include mutations\n",
    "df = df.merge(muts, how=\"left\")\n",
    "df[\"Phenotype\"].fillna(\"WT\", inplace=True)\n",
    "df[\"Variant_Classification\"].fillna(\"-\", inplace=True)\n",
    "\n",
    "# Load altered E3 ligases\n",
    "ubiquitins = []\n",
    "with open(\"internal/curated_ub_du.lst\") as fd:\n",
    "    ubiquitins = [l.rstrip() for l in fd]\n",
    "\n",
    "e3_ligases = pd.read_csv(path_mutations,sep=\"\\t\",compression=\"gzip\")\n",
    "e3_ligases = e3_ligases[e3_ligases[\"Hugo_Symbol\"].isin(ubiquitins)]\n",
    "e3_ligases = e3_ligases[(e3_ligases[\"Phenotype\"]==\"Nonsense_Mutation\")|(e3_ligases[\"Phenotype\"]==\"Frame_Shift_Del\")|(e3_ligases[\"Phenotype\"]==\"Frame_Shift_Ins\")|(e3_ligases[\"Phenotype\"]==\"Missense_Mutation\")|(e3_ligases[\"Phenotype\"].str.contains(\"In_Frame\"))|(e3_ligases[\"Phenotype\"]==\"Nonstop_Mutation\")|(e3_ligases[\"Phenotype\"]==\"Splice_Site\")]\n",
    "e3_ligases = e3_ligases.groupby([\"Matchable_Sample_ID\"], as_index=False).agg({\"Hugo_Symbol\":concat})\n",
    "e3_ligases.rename(columns={\"Hugo_Symbol\":\"Ubiquitinases_Mutated\"}, inplace=True)\n",
    "\n",
    "df = df.merge(e3_ligases, how=\"left\")\n",
    "df[\"Ubiquitinases_Mutated\"].fillna(\"-\", inplace=True)\n",
    "\n",
    "# Annotate samples with upstream mutated E3 ligases\n",
    "df_ppi = pd.read_csv(ppi_e3, sep=\"\\t\")\n",
    "d_mapping = {}\n",
    "for hugo in rna_rppa_cna_muts[\"Hugo_Symbol\"].unique():\n",
    "    d_mapping[hugo]=list(df_ppi[(df_ppi[\"Hugo_SUB\"]==hugo)][\"Hugo_E3\"].values)\n",
    "    \n",
    "df[\"Altered_E3_Ligases\"] = df.apply(lambda row: find_altered_E3(row,d_mapping), axis=1)\n",
    "\n",
    "# Include epitopes\n",
    "df = df.merge(df_antibodies[[\"Protein\", \"Epitope\"]].drop_duplicates())\n",
    "\n",
    "# Disrupt epitopes\n",
    "df[\"Disrupt_Epitope\"] = df.apply(lambda row: is_in_recognition(row), axis=1)\n",
    "\n",
    "df.drop_duplicates().to_csv(\"data/rppa_matched.tsv.gz\", sep=\"\\t\",index=False,compression=\"gzip\")\n",
    "print(\"Samples:\", len(set(df[\"Matchable_Sample_ID\"].unique())))\n",
    "print(\"Proteins:\", len(set(df[\"Protein\"].unique())))\n",
    "print(\"Symbols:\", len(set(df[\"Hugo_Symbol\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 6909\n",
      "Proteins: 236\n",
      "Symbols: 193\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples:\", len(set(df[\"Matchable_Sample_ID\"].unique())))\n",
    "print(\"Proteins:\", len(set(df[\"Protein\"].unique())))\n",
    "print(\"Symbols:\", len(set(df[\"Hugo_Symbol\"].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCLE data\n",
    "\n",
    "Obtained from https://portals.broadinstitute.org/ccle/data and saved in ``ccle`` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell line specific RPPA data\n",
    "\n",
    "Combine the data with manual curation of some antibodies of interest (Included in the MD anderson dataset) and match for each antibody its HUGO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell lines:  899\n",
      "Antibodies:  214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"external/ccle/CCLE_RPPA_20180123.csv\", sep=\",\")\n",
    "df.rename(columns={\"Unnamed: 0\":\"Matchable_Sample_ID\"},inplace=True)\n",
    "df_rppa = df.melt(id_vars=\"Matchable_Sample_ID\",value_vars=df.columns.values[1:],value_name=\"RPPA_VALUES\",var_name=\"Protein\") # Melt it\n",
    "\n",
    "# Annotations from Broad\n",
    "df_antibody = pd.read_csv('internal/antibody_ccle.csv', sep=\",\")[[\"Protein\",\"Hugo_Symbol\"]].drop_duplicates()\n",
    "\n",
    "# Merge with CCLE\n",
    "df_ccle = pd.merge(df_rppa, df_antibody)\n",
    "df_ccle.to_csv('data/ccle_rppa.tsv' ,sep=\"\\t\", index=False)\n",
    "\n",
    "print('Cell lines: ', len(df_ccle[\"Matchable_Sample_ID\"].unique()))\n",
    "print('Antibodies: ', len(df_ccle[\"Protein\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA data\n",
    "\n",
    "Filter to keep only information of proteins with RPPA data and compute the log2 of the RPKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_rna = pd.read_csv(\"external/ccle/CCLE_DepMap_18q3_RNAseq_RPKM_20180718.gct\", sep=\"\\t\", skiprows=2)\n",
    "df_rna = df_rna.melt(id_vars=[\"Name\",\"Description\"], value_vars=df_rna.columns.values[2:], value_name=\"RPKM\", var_name=\"Sample_ID\")\n",
    "df_rna.rename(columns={\"Description\":\"Hugo_Symbol\"}, inplace=True)\n",
    "df_rna[\"Matchable_Sample_ID\"]= df_rna.apply(lambda row: row[\"Sample_ID\"].split(\" \")[0], axis=1)\n",
    "\n",
    "hugos = pd.read_csv('data/ccle_rppa.tsv', sep=\"\\t\")[\"Hugo_Symbol\"].unique()\n",
    "df_rna = df_rna[df_rna[\"Hugo_Symbol\"].isin(hugos)]\n",
    "\n",
    "df_rna[\"log2(RPKM)\"] = np.log2(df_rna[\"RPKM\"] + 0.0001)\n",
    "df_rna.drop([\"Name\",\"Sample_ID\",\"RPKM\"],axis=1,inplace=True)\n",
    "df_rna.to_csv(\"data/ccle_rna.tsv.gz\", sep=\"\\t\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNA data\n",
    "\n",
    "Filter to keep only information of proteins with RPPA data.  \n",
    "Classify the data into 5 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def classify(row, mean_high, mean_low):\n",
    "    high = mean_high if row[\"High\"] is np.nan else row[\"High\"]\n",
    "    low = mean_low if row[\"Low\"] is np.nan else row[\"Low\"]\n",
    "    \n",
    "    if row[\"CNA_RAW\"] > 0: # amp\n",
    "        if row[\"CNA_RAW\"] > high:\n",
    "            return 2\n",
    "        elif row[\"CNA_RAW\"] > 0.3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if row[\"CNA_RAW\"] < low:\n",
    "            return -2\n",
    "        elif row[\"CNA_RAW\"] < -0.3:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "df_cna = pd.read_csv(\"external/ccle/CCLE_copynumber_byGene_2013-12-03.txt\", sep=\"\\t\")\n",
    "df_cna = df_cna.melt(id_vars=[\"EGID\",\"SYMBOL\",\"CHR\",\"CHRLOC\",\"CHRLOCEND\"],value_vars=df_cna.columns.values[5:],value_name=\"CNA\",var_name=\"Matchable_Sample_ID\")\n",
    "df_cna.drop([\"EGID\",\"CHRLOC\",\"CHR\",\"CHRLOCEND\"],axis=1,inplace=True)\n",
    "df_cna.rename({\"SYMBOL\":\"Hugo_Symbol\",\"CNA\":\"CNA_RAW\"},axis=1,inplace=True)\n",
    "\n",
    "hugos = pd.read_csv('data/ccle_rppa.tsv', sep=\"\\t\")[\"Hugo_Symbol\"].unique()\n",
    "df_cna = df_cna[df_cna[\"Hugo_Symbol\"].isin(hugos)]\n",
    "\n",
    "# Load thresholds to set up a ABSOLUTE CNA\n",
    "df_thresholds = pd.read_csv(\"internal/CCLE_copynumber_2012-04-05.seg.sample_cutoffs.txt\", sep=\"\\t\", skiprows=1)\n",
    "df_cna = pd.merge(df_cna, df_thresholds, how=\"left\")\n",
    "\n",
    "mean_high = df_cna[\"High\"].mean()       \n",
    "mean_low = df_cna[\"Low\"].mean()       \n",
    "df_cna[\"CNA\"] = df_cna.apply(lambda row: classify(row, mean_high, mean_low), axis=1)\n",
    "df_cna.drop([\"CNA_RAW\",\"High\",\"Low\"], axis=1, inplace=True)\n",
    "df_cna[\"Matchable_Sample_ID\"] = df_cna.apply(lambda row: row[\"Matchable_Sample_ID\"], axis=1)\n",
    "df_cna.to_csv('data/ccle_cna.tsv.gz', sep=\"\\t\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutational data\n",
    "\n",
    "All alterations in the same gene are combined   \n",
    "Phenotype is selected from this order of priority  \n",
    "CCDS  is included from the transcript ID\n",
    "\n",
    "The CCDS file is downloaded from http://grch37.ensembl.org/biomart/martview/08bfd74632dad1fba47faf5ad3a5fe22 in TSV format. The downloaded file is named as ``ccds_ensembl.tsv`` and the columns renamed to: ``Gene``, ``Transcript``and ``CCDS``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "TCGA_PRIORITIES = [\"Splice_Site\",\"Nonsense_Mutation\",\"Frame_Shift_Del\",\"Frame_Shift_Ins\",\"Nonstop_Mutation\",\"Translation_Start_Syte\",\"In_Frame_Del\",\"In_Frame_Ins\",\"Missense_Mutation\",\"Intron\",\"Silent\",\"5'UTR\",\"3'UTR\",\"IGR\",\"5'Flank\",\"3'Flank\"]\n",
    "DNP_REGEX = re.compile(\"([0-9_]+)[A-Z]+>[A-Z]+\")#66_66G>GG\n",
    "DEL_REGEX = re.compile(\"[A-Z\\*]*([0-9]+)del\")\n",
    "INS_REGEX = re.compile(\"([0-9_]+)+ins[A-Z\\*]+\")\n",
    "OTHER_REGEX = re.compile(\"([0-9_]+)[A-Z\\*]+>[A-Z\\*]+\")#66_66G>GG\n",
    "\n",
    "def concat(grp):\n",
    "    l = list(grp)\n",
    "    return \",\".join([str(e) for e in list(grp)])\n",
    "\n",
    "def select_phenotype(row):\n",
    "    values = row[\"Variant_Classification\"].split(\",\")\n",
    "    for priority in TCGA_PRIORITIES:\n",
    "        if priority in values:\n",
    "            return priority\n",
    "    return \"-\"\n",
    "\n",
    "def get_protein_mutation(row):\n",
    "    try:\n",
    "        mutation=row[\"Protein_Change\"].split(\".\")[1]\n",
    "    except:\n",
    "        return \".\"\n",
    "    return mutation\n",
    "\n",
    "def get_protein_position(row):\n",
    "    if (row[\"Variant_Classification\"]==\"Missense_Mutation\" or row[\"Variant_Classification\"]==\"Silent\") and row[\"Variant_Type\"]==\"SNP\": \n",
    "        return row[\"protein_mutation\"][1:-1]\n",
    "    elif (row[\"Variant_Classification\"]==\"Missense_Mutation\" or row[\"Variant_Classification\"]==\"Silent\") and row[\"Variant_Type\"]==\"DNP\": \n",
    "        m = re.search(DNP_REGEX, row[\"protein_mutation\"])\n",
    "        if m:\n",
    "            return m.group(1).replace(\"_\",\"-\")\n",
    "        return \".\"\n",
    "    elif row[\"Variant_Classification\"]==\"In_Frame_Del\" or row[\"Variant_Classification\"]==\"In_Frame_Ins\":\n",
    "        m = re.search(DEL_REGEX,row[\"protein_mutation\"])\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "        m = re.search(INS_REGEX,row[\"protein_mutation\"])\n",
    "        if m:\n",
    "            return m.group(1).replace(\"_\",\"-\")\n",
    "        m = re.search(OTHER_REGEX,row[\"protein_mutation\"])\n",
    "        if m:\n",
    "            return m.group(1).replace(\"_\",\"-\")\n",
    "        return \".\"\n",
    "    return \".\"\n",
    "\n",
    "\n",
    "df_mutations = pd.read_csv(\"external/ccle/CCLE_DepMap_18q3_maf_20180718.txt\", sep=\"\\t\", low_memory=False)\n",
    "df_mutations[\"Matchable_Sample_ID\"] = df_mutations[\"Tumor_Sample_Barcode\"]\n",
    "df_mutations = df_mutations[[\"Hugo_Symbol\",\"Chromosome\",\"Start_position\",\"End_position\",\"Strand\",\"Variant_Classification\",\"Reference_Allele\",\"Tumor_Seq_Allele1\",\"Matchable_Sample_ID\",\"Protein_Change\",\"Codon_Change\",\"Annotation_Transcript\",\"Variant_Type\"]].drop_duplicates()\n",
    "\n",
    "# Add CCDS\n",
    "df_mutations[\"Transcript\"] = df_mutations.apply(lambda row: row[\"Annotation_Transcript\"].split(\".\")[0], axis=1)\n",
    "df_cds = pd.read_csv('external/ccds_ensembl.tsv', sep=\"\\t\")[[\"CCDS\",\"Transcript\"]].drop_duplicates()\n",
    "df_m = pd.merge(df_mutations, df_cds)\n",
    "df_mutations_cds = df_m[~pd.isnull(df_m[\"CCDS\"])].copy()\n",
    "df_mutations_cds.rename(columns={\"CCDS\":\"CCDS_BASIC\"}, inplace=True)\n",
    "df_uniprot = pd.read_csv('data/uniprot_isoforms.tsv', sep=\"\\t\")\n",
    "df_uniprot[\"CCDS_BASIC\"] = df_uniprot.apply(lambda row: str(row[\"CCDS\"]).split(\".\")[0], axis=1)\n",
    "df_mutations_cds = pd.merge(df_uniprot[[\"Hugo_Symbol\",\"CCDS\",\"CCDS_BASIC\",\"Entry_Isoform\",\"Entry\"]].drop_duplicates(),df_mutations_cds)\n",
    "df_mutations_cds[\"protein_mutation\"] = df_mutations_cds.apply(lambda row: get_protein_mutation(row),axis=1)\n",
    "df_mutations_cds[\"Protein_position\"] = df_mutations_cds.apply(lambda row: get_protein_position(row),axis=1)\n",
    "\n",
    "mutations_sample = df_mutations_cds[[\"Matchable_Sample_ID\",\"Hugo_Symbol\",\"Chromosome\",\"Start_position\",\"End_position\",\"Strand\",\"Reference_Allele\",\"Tumor_Seq_Allele1\",\"Protein_position\",\"protein_mutation\",\"Variant_Classification\",\"CCDS\",\"Variant_Type\"]].drop_duplicates()\n",
    "mutations_sample_u = mutations_sample.groupby([\"Hugo_Symbol\",\"Matchable_Sample_ID\",\"CCDS\"],as_index=False).agg({\"Chromosome\":concat,\"Start_position\":concat,\"End_position\":concat,\"Strand\":concat,\"Variant_Classification\":concat,\"Reference_Allele\":concat,\"Tumor_Seq_Allele1\":concat,\"Protein_position\":concat,\"protein_mutation\":concat,\"Variant_Type\":concat})\n",
    "mutations_sample_u[\"Phenotype\"] = mutations_sample_u.apply(lambda row: select_phenotype(row), axis=1)\n",
    "mutations_sample_u = mutations_sample_u.drop_duplicates()\n",
    "mutations_sample_u[\"Matchable_Sample_ID\"] = mutations_sample_u.apply(lambda row: row[\"Matchable_Sample_ID\"], axis=1)\n",
    "mutations_sample_u.drop_duplicates().to_csv('data/ccle_muts.tsv.gz', sep=\"\\t\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass spectrometry data\n",
    "\n",
    "Mass-pectrometry data from human high-grade serous ovarian cancer and breast cancer TCGA cohorts\n",
    "\n",
    "Download the data in ``external/tcga_ms`` using https://github.com/compgenome365/TCGA-Assembler-2 and executing with R:\n",
    "```R\n",
    "DownloadCPTACData(cancerType = \"BRCA\",assayPlatform = \"proteome_iTRAQ\", saveFolderName = 'external')\n",
    "DownloadCPTACData(cancerType = \"OV\",assayPlatform = \"proteome_iTRAQ\", saveFolderName = 'external')\n",
    "```\n",
    "\n",
    "Data was download on 20/10/2018\n",
    "\n",
    "- Filter for only iTRAQ datasets i.e. BRCA, OV (discard non itraq data)\n",
    "- Use the \"Unshared\" measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins  11064\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "list_dfs = []\n",
    "for filename in glob.iglob('external/tcga_ms/*.txt'):\n",
    "    m = re.search('external/tcga_ms/([A-Z]+)__.*\\.txt', filename)\n",
    "    if m:\n",
    "        cancer_type = m.group(1)\n",
    "        df = pd.read_csv(filename,sep=\"\\t\")\n",
    "        df[\"Cancer_Type\"] = cancer_type\n",
    "        df_melted = df.melt(id_vars=list(df.columns.values[0:5])+[\"Cancer_Type\"],value_vars=df.columns.values[5:-1],var_name=\"SAMPLE_INFO\",value_name=\"log_ratio(iTRAQ)\")\n",
    "        df_melted = df_melted[df_melted[\"SAMPLE_INFO\"].str.contains(\"Unshared-Log-Ratio\")] # select unshared spectral\n",
    "        if df_melted.shape[0] >0:\n",
    "            df_melted[\"Matchable_Sample_ID\"] = df_melted.apply(lambda row: row[\"SAMPLE_INFO\"][0:12],axis=1) \n",
    "            df_melted[\"Hugo_Symbol\"] = df_melted[\"Gene\"]\n",
    "            df_melted = df_melted[[\"Hugo_Symbol\",\"Cancer_Type\",\"Matchable_Sample_ID\",\"log_ratio(iTRAQ)\"]].drop_duplicates() \n",
    "            list_dfs.append(df_melted)\n",
    "\n",
    "df = pd.concat(list_dfs)\n",
    "df.drop_duplicates().to_csv('data/MS-data-parsed.tsv.gz', sep=\"\\t\", index=False, compression=\"gzip\")\n",
    "\n",
    "print('Proteins ', len(df[\"Hugo_Symbol\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA data\n",
    "\n",
    "The input data is the same as for TCGA RNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:  201\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read samples with data\n",
    "df_ms = pd.read_csv(\"data/MS-data-parsed.tsv.gz\", sep=\"\\t\", compression=\"gzip\")\n",
    "samples = df_ms[\"Matchable_Sample_ID\"].unique()\n",
    "ttypes = df_ms[\"Cancer_Type\"].unique()\n",
    "\n",
    "\n",
    "df_info_samples = pd.read_csv(\"external/tcga_rna/merged_sample_quality_annotations.tsv\",sep=\"\\t\")\n",
    "samples_filtered = df_info_samples[(df_info_samples[\"platform\"]==\"IlluminaHiSeq_RNASeqV2\")&(~df_info_samples[\"Do_not_use\"])&(~pd.isnull(df_info_samples[\"cancer type\"]))][[\"aliquot_barcode\",\"cancer type\"]].drop_duplicates()\n",
    "\n",
    "df_rna = pd.read_csv(\"external/tcga_rna/EBPlusPlusAdjustPANCAN_IlluminaHiSeq_RNASeqV2.geneExp.tsv\",sep=\"\\t\")\n",
    "df_rna[\"Hugo_Symbol\"] = df_rna.apply(lambda row: row[\"gene_id\"].split(\"|\")[0],axis=1)\n",
    "df_rna = df_rna[df_rna[\"Hugo_Symbol\"]!=\"?\"]\n",
    "df_rna.drop(\"gene_id\",axis=1,inplace=True)\n",
    "\n",
    "df_rna = df_rna.melt(id_vars=\"Hugo_Symbol\",value_name=\"RSEM\",var_name=\"aliquot_barcode\").merge(samples_filtered,how=\"right\")\n",
    "df_rna.rename(columns={\"aliquot_barcode\":\"Tumor_Sample_Barcode\", \"cancer type\": \"Cancer_Type\"},inplace=True)\n",
    "df_rna[\"Matchable_Sample_ID\"] = df_rna[\"Tumor_Sample_Barcode\"].str[0:12]\n",
    "df_rna = df_rna[(df_rna[\"Cancer_Type\"].isin(ttypes)) & (df_rna[\"Matchable_Sample_ID\"].isin(samples))]\n",
    "df_rna.drop(columns=[\"Tumor_Sample_Barcode\"],inplace=True)\n",
    "df_rna=df_rna.groupby([\"Hugo_Symbol\",\"Matchable_Sample_ID\",\"Cancer_Type\"],as_index=False).agg({\"RSEM\":np.nanmean})\n",
    "df_rna[\"log2(RSEM)\"] = np.log2(df_rna[\"RSEM\"] + 0.0001)\n",
    "df_rna.to_csv('data/tcga_rna_ms.tsv.gz', sep=\"\\t\", compression=\"gzip\", index=False)\n",
    "print('Samples: ', len(df_rna[\"Matchable_Sample_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNA data\n",
    "\n",
    "The input data is the same as for TCGA CNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "df_ms = pd.read_csv('data/MS-data-parsed.tsv.gz', sep=\"\\t\", compression=\"gzip\")\n",
    "samples = df_ms[\"Matchable_Sample_ID\"].unique()\n",
    "ttypes = df_ms[\"Cancer_Type\"].unique()\n",
    "\n",
    "# Read CNA data\n",
    "list_values = []\n",
    "for file in os.listdir('external/tcga_cna/'):\n",
    "    cancer_type = file.split('-')[0].replace('gdac.broadinstitute.org_', '')\n",
    "    if not(cancer_type in ttypes):\n",
    "            continue\n",
    "    tar = tarfile.open(\"external/tcga_cna/{}\".format(file), \"r:gz\")\n",
    "    f = tar.extractfile('{}/all_thresholded.by_genes.txt'.format(file.replace('.tar.gz', '')))\n",
    "    df = pd.read_csv(f, sep=\"\\t\", error_bad_lines=False)\n",
    "    df_cna = pd.melt(df,id_vars=[\"Gene Symbol\",\"Locus ID\",\"Cytoband\"],var_name=\"Tumor_Sample_Barcode\",value_name=\"CNA\")\n",
    "    df_cna[\"Matchable_Sample_ID\"] = df_cna[\"Tumor_Sample_Barcode\"].str[0:12]\n",
    "    df_cna.drop(\"Tumor_Sample_Barcode\",axis=1,inplace=True)\n",
    "    df_cna = df_cna[df_cna[\"Matchable_Sample_ID\"].isin(samples)]\n",
    "    list_values.append(df_cna)\n",
    "\n",
    "df_cna = pd.concat(list_values).drop_duplicates()\n",
    "df_cna.rename(columns={\"Gene Symbol\":\"Hugo_Symbol\"}, inplace=True)\n",
    "df_cna.to_csv('data/CNA_filtered_ms.tsv.gz', compression=\"gzip\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteins involved in ubuquitintation\n",
    "\n",
    "Manually created list: internal/curated_ub_du.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "human_proteins=`cat internal/curated_ub_du.lst | wc -l`\n",
    "echo \"Human proteins ${human_proteins}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E3 ligase substrate interactions\n",
    "\n",
    "Download a curated list of E3 ligases substrate interactions from http://pnet.kaist.ac.kr/e3net/  \n",
    "Add manual anotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins involved 833\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_uniprot = pd.read_csv('data/uniprot_isoforms.tsv', sep=\"\\t\")[[\"Hugo_Symbol\",\"Entry\"]].drop_duplicates()\n",
    "df_interactions = pd.read_excel('external/E3Net_E3-SubRelation.xlsx')\n",
    "\n",
    "# Filter human interactions\n",
    "df_interactions_human = df_interactions[df_interactions[\"SUB_ID\"].str.contains(\"HUMAN\")]\n",
    "\n",
    "# Add Hugo to E3\n",
    "df_interactions_human = df_interactions_human.merge(df_uniprot, right_on=[\"Entry\"], left_on=[\"E3_AC\"])\n",
    "df_interactions_human.rename(columns={\"Hugo_Symbol\":\"Hugo_E3\"}, inplace=True)\n",
    "\n",
    "# Add Hugo to substrate\n",
    "df_interactions_human = df_interactions_human.merge(df_uniprot, right_on=[\"Entry\"], left_on=[\"SUB_AC\"])\n",
    "df_interactions_human.rename(columns={\"Hugo_Symbol\":\"Hugo_SUB\"}, inplace=True)\n",
    "\n",
    "df_interactions_human.drop([\"Entry_x\",\"Entry_y\"],axis=1,inplace=True)\n",
    "\n",
    "# Add manual interactions\n",
    "df_manual = pd.DataFrame([[\"APC_HUMAN\",\"P25054\",\"APC\",\"APC\",\"COMPLEX\",\"APC\",\"CTNNB1\",\"P35222\",\"-\",\"-\",\"APC\",\"CTNNB1\"]], columns=df_interactions_human.columns.values)\n",
    "df_final = pd.concat([df_interactions_human,df_manual])\n",
    "\n",
    "df_final.to_csv('data/E3_target_annotated_interations.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "print('Proteins involved', len(df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein-protein interactions\n",
    "\n",
    "Download the data from https://stringdb-static.org/download/protein.links.detailed.v10.5/9606.protein.links.detailed.v10.5.txt.gz and https://string-db.org/mapping_files/uniprot_mappings/full_uniprot_2_string.04_2015.tsv.gz      \n",
    "Map Hugo symbols to UniProt  \n",
    "Filter out interaction without a protein involved in ubiquitination  \n",
    "Filter out pairs with a score below 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fran/Downloads/yes/envs/regression/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions:  2568513\n",
      "Proteins:  18403\n",
      "E3 ligases:  566\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_annotated_interactions = pd.read_csv('external/9606.protein.links.detailed.v10.5.txt.gz', sep=\" \", header=0, compression=\"gzip\")\n",
    "df_annotated_interactions = df_annotated_interactions[df_annotated_interactions[\"combined_score\"]>300]  # filter out below 300\n",
    "\n",
    "# Create a mapping of string to uniprot\n",
    "df_uniprot = pd.read_csv('data/uniprot_isoforms.tsv', sep=\"\\t\")[[\"Hugo_Symbol\",\"Entry\"]].drop_duplicates()\n",
    "df_ids = pd.read_csv('external/full_uniprot_2_string.04_2015.tsv.gz', sep=\"\\t\", header=None, names=[\"SPECIE\",\"UNIPROT_NAME\",\"STRING_ID\",\"IDENTITY\",\"SCORE\"])\n",
    "df_ids = df_ids[df_ids['SPECIE'] == 9606]  # keep only human\n",
    "df_ids[\"Entry\"] = df_ids.apply(lambda row: row[\"UNIPROT_NAME\"].split(\"|\")[0],axis=1)\n",
    "df_ids[\"NAME\"] = df_ids.apply(lambda row: row[\"UNIPROT_NAME\"].split(\"|\")[1],axis=1)\n",
    "df_ids[\"STRING_ID\"] = df_ids.apply(lambda row: \"9606.\"+row[\"STRING_ID\"],axis=1)\n",
    "df_ids = pd.merge(df_uniprot, df_ids, how=\"right\")\n",
    "df_ids = df_ids[[\"Hugo_Symbol\",\"Entry\",\"STRING_ID\"]].drop_duplicates()\n",
    "df_ids = df_ids[~pd.isnull(df_ids[\"Hugo_Symbol\"])]\n",
    "\n",
    "# Annotate protein 1\n",
    "df_annotated_interactions = pd.merge(df_ids, df_annotated_interactions[[\"protein1\",\"protein2\",\"experimental\",\"combined_score\"]].drop_duplicates(), left_on=[\"STRING_ID\"], right_on=\"protein1\")\n",
    "df_annotated_interactions.rename(columns={\"Hugo_Symbol\":\"Hugo1\", \"Entry\":\"Entry1\"},inplace=True)\n",
    "df_annotated_interactions.drop([\"STRING_ID\",\"protein1\"], axis=1, inplace=True)\n",
    "df_annotated_interactions.drop_duplicates(inplace=True)\n",
    "df_annotated_interactions.rename(columns={\"Hugo_Symbol\":\"Hugo2\",\"Entry\":\"Entry2\"},inplace=True)\n",
    "\n",
    "# Annotate protein 2\n",
    "df_annotated_interactions = pd.merge(df_ids ,df_annotated_interactions, left_on=[\"STRING_ID\"], right_on=\"protein2\")\n",
    "df_annotated_interactions = df_annotated_interactions.drop([\"STRING_ID\",\"protein2\"],axis=1)\n",
    "df_annotated_interactions.rename(columns={\"Hugo_Symbol\":\"Hugo2\",\"Entry\":\"Entry2\"}, inplace=True)\n",
    "\n",
    "df_annotated_interactions.to_csv('data/ppi_all_targets.tsv.gz', sep=\"\\t\", index=False,compression=\"gzip\")\n",
    "\n",
    "print('Interactions: ', len(df_annotated_interactions))\n",
    "print('Proteins: ', len(df_annotated_interactions[\"Hugo1\"].unique()))\n",
    "\n",
    "\n",
    "human_ubiquitins_names = []\n",
    "with open('internal/curated_ub_du.lst') as f:\n",
    "    for line in f:\n",
    "        human_ubiquitins_names.append(line.strip())\n",
    "\n",
    "print('E3 ligases: ', len(df_annotated_interactions[df_annotated_interactions[\"Hugo1\"].isin(human_ubiquitins_names)][\"Hugo1\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTMs\n",
    "\n",
    "Downloads datasets (phosphorilation sites and ubiquitination sites) from https://www.phosphosite.org/ \n",
    "(Version Thu Oct 04 11:40:34 EDT 2018)\n",
    "\n",
    "For each dataset we included integer position of the modification and only human data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phosphorilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phospho = pd.read_csv(\"external/Phosphorylation_site_dataset.gz\", sep=\"\\t\", skiprows=3)\n",
    "df_phospho = df_phospho[df_phospho[\"ORGANISM\"]==\"human\"]\n",
    "df_phospho[\"Position\"] = df_phospho.apply(lambda row: int(row[\"MOD_RSD\"].split(\"-\")[0][1:]),axis=1)\n",
    "df_phospho.to_csv(\"data/phosphorylation_sites_human.tsv.gz\", sep=\"\\t\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ubiquitination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fran/Downloads/yes/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_ub = pd.read_csv(\"external/Ubiquitination_site_dataset.gz\", sep=\"\\t\", skiprows=3)\n",
    "df_ub = df_ub[df_ub[\"ORGANISM\"]==\"human\"]\n",
    "df_ub[\"Position\"] = df_ub.apply(lambda row: int(row[\"MOD_RSD\"].split(\"-\")[0][1:]),axis=1)\n",
    "df_ub.to_csv(\"data/ubiquitination_sites_human.tsv.gz\", sep=\"\\t\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
